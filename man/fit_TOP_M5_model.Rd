% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_TOP_models.R
\name{fit_TOP_M5_model}
\alias{fit_TOP_M5_model}
\title{Fit TOP model}
\usage{
fit_TOP_M5_model(
  all_training_data,
  all_training_data_files,
  model.file,
  logistic.model = FALSE,
  out.dir = "TOP_samples",
  transform = c("asinh", "log2", "sqrt", "none"),
  partitions = 1:10,
  n.iter = 2000,
  n.burnin = floor(n.iter/2),
  n.chains = 3,
  n.thin = max(1, floor((n.iter - n.burnin)/1000)),
  n.cores = length(partitions),
  quiet = FALSE
)
}
\arguments{
\item{all_training_data}{A list of the assembled training data of all partitions.}

\item{all_training_data_files}{A vector of the assembled training data
files of all partitions. If all_training_data is missing,
it will load the training data from all_training_data_files.}

\item{model.file}{File name containing the TOP model written in BUGS code.}

\item{logistic.model}{Logical; if TRUE, use the logistic version of TOP model.}

\item{out.dir}{Output directory for TOP model posterior samples.}

\item{transform}{Type of transformation for ChIP counts.
Possible values are "asinh", "log2", "sqrt", and "none" (no transformation).
Only needed when logistic.model is FALSE.}

\item{partitions}{A vector of selected partition(s) to run.
(default: all 10 partitions (1:10))}

\item{n.iter}{Number of total iterations per chain (including burn in).}

\item{n.burnin}{Length of burn in samples,
i.e. number of iterations to discard at the beginning.
Default is n.iter/2, that is, discarding the first half of the simulations.}

\item{n.chains}{Number of Markov chains (default: 3).}

\item{n.thin}{Thinning rate, must be a positive integer.
Default is max(1, floor(n.chains * (n.iter-n.burnin) / 1000))
which will only thin if there are at least 2000 simulations.}

\item{n.cores}{Number of cores to use in parallel
(default: equal to the number of partitions).}

\item{quiet}{Logical, whether to suppress stdout in jags.model().}
}
\description{
Fit TOP model (using M5 bins) for selected partitions in parallel.
}
