---
title: 'Train TOP model'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Train TOP model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = '#>'
)
```

Load TOP R package
---------------------

```{r load-TOP-package, eval = FALSE}
library(TOP)
```


Prepare training data
---------------------

**Step 1: Prepare training data for each TF in each cell type**

For each TF in each cell type, prepare training data for candidate binding sites:
including: PWM scores, DNase (or ATAC) bins, 
and measured TF occupancy (from ChIP-seq data).

You can follow this [page](data_preparation.html) to prepare training data.

Create a data frame listing all the TFs and cell types. 
The data frame should have three columns:
TF names, cell types, and paths to the training data files, like:

|   tf_name    |   cell_type   |        data_file         |
|:------------:|:-------------:|:------------------------:|
|     CTCF     |     K562      |   CTCF.K562.data.rds     |
|     CTCF     |     A549      |   CTCF.A549.data.rds     |
|     CTCF     |    GM12878    |   CTCF.GM12878.data.rds  |
|     NRF1     |     K562      |   NRF1.K562.data.rds     |
|     MYC      |     K562      |   MYC.K562.data.rds      |
|     ...      |     ...       |   ...                    |


**Step 2: Assemble training data for all TF-cell type combinations**

Assemble training data for all training TF-cell type 
combinations, then split training data into 10 partitions.

Select the odd chromosomes as training set.
```{r assemble-TOP-training-data, eval = FALSE}
all_training_data <- assemble_TOP_training_data(tf_cell_table,
                                                logistic.model = FALSE,
                                                chip_colname = 'chip',
                                                training_chrs = paste0('chr', seq(1,21,2)), 
                                                n.partitions = 10)
```

Save a table listing all TF and cell type combinations. 
This will be used later to extract regression coefficients.
```{r tf-cell-combos, eval = FALSE}
tf_cell_combos <- unique(all_training_data[[1]][, c('tf_id', 'cell_id', 'tf_name', 'cell_type')])
```

Train TOP models using assembled training data
----------------------------------------------

Fit TOP model for each partition separately, and save the posterior samples.

We can set the following parameters for Gibbs sampling: 

- n.iter: number of total iterations per chain (including burn-in iterations).
- n.burnin: number of burn-in iterations, i.e. number of iterations to discard at the beginning.
- n.chains: number of Markov chains.
- n.thin: thinning rate, must be a positive integer.

This step usually takes a long time if we have many TFs and many cell types. 
To save computation time, we can also run the partitions 
(choose which partition to run, e.g. `partitions=3`) 
in parallel on separate compute nodes. 

**Note**: need to install `R2jags` package to fit TOP models using JAGS.

```{r train-TOP-model, eval = FALSE}
library(R2jags)

TOP_samples_files <- fit_TOP_model(all_training_data, 
                                   model.file = '../jags/TOP_M5_model_jags.bug',
                                   logistic.model = FALSE,
                                   out.dir = 'TOP_fit',
                                   transform = 'asinh', # asinh transform ChIP-seq counts
                                   partitions = 1:10,
                                   n.iter = 10000,
                                   n.burnin = 5000,
                                   n.chains = 3,
                                   n.thin = 5,
                                   quiet = TRUE)
```

Combine TOP posterior samples from all partitions and extract the posterior mean of the regression coefficients
----------------------------------------------------------------------------------------------------------------

After the training is done, we can combine the posterior samples from the partitions,
and obtain the posterior mean of the regression coefficients.

Combine TOP posterior samples from the 10 partitions.
```{r combine-TOP-coef, eval = FALSE}
TOP_samples <- combine_TOP_samples(TOP_samples_files)
dim(TOP_samples)
```

Extract posterior mean coefficients for all three levels.
```{r extract-TOP-mean-coef, eval = FALSE}
TOP_mean_coef <- extract_TOP_mean_coef(TOP_samples, tf_cell_combos)
```

Save the posterior samples and posterior mean coefficients.
```{r save-samples-coef, eval = FALSE}
saveRDS(TOP_samples, 'TOP_fit/TOP_M5_combined_posterior_samples.rds')
saveRDS(TOP_mean_coef, 'TOP_fit/TOP_M5_posterior_mean_coef.rds')
```

We will provide pre-trained models using ENCODE data
[here](https://users.cs.duke.edu/~amink/software/).

To make predictions for TF occupancy using new DNase- or ATAC-seq data 
using trained model coefficients,
see this [page](predict_TF_occupancy_with_trained_model.html)

