---
title: 'Train TOP model'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Train TOP model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = '#>'
)
```

Load TOP R package
---------------------

```{r load-TOP-package, eval = FALSE}
library(TOP)
```


Prepare training data
---------------------

**Step 1: Prepare training data for each TF in each cell type**

For each TF in each cell type, prepare training data for candidate binding sites:
including: PWM scores, DNase (or ATAC) bins, 
and measured TF occupancy (from ChIP-seq data).

You can follow this [page](data_preparation.html) to prepare training data.

Create a tab delimited table listing all the TFs and cell types. 
The table should have three columns:
TF names, cell types, and paths to the training data files.

For example:
```{r create-tf_cell_table, eval=FALSE}
tf_cell_table <- data.frame(tf_name = c('TF1', 'TF2', ...),
                            cell_type = c('cell1', 'cell2', ...),
                            data_file = c('data.file1', 'data.file2', ...))

write.table(tf_cell_table, "tf_cell_table.tsv", sep = '\t', 
            col.names = TRUE, row.names = FALSE, quote = FALSE)
```

**Step 2: Assemble training data for all TF-cell type combinations**

Assemble training datasets for all training TF-cell type 
combinations, then split training data into 10 partitions.

Select the odd chromosomes as training set.
```{r assemble-TOP-training-data, eval = FALSE}
training_data_partitions <- assemble_TOP_training_data(tf_cell_table_file = 'tf_cell_table.tsv',
                                                       training_data_dir = 'training_data_dir/', 
                                                       training_data_name = 'TOP_training_data',
                                                       chip_colname = 'chip',
                                                       training_chrs = paste0('chr', seq(1,21,2)), 
                                                       n.partitions = 10)
```

Save a table listing all TF and cell type combinations. 
This will be used later to extract regression coefficients.
```{r}
tf_cell_combos <- unique(training_data_partitions[[1]][, c('tf_id', 'cell_id', 'tf_name', 'cell_type')])
```

Train TOP models using assembled training data
----------------------------------------------

Fit TOP model for each partition separately, and save the posterior samples.

We can set the following parameters for Gibbs sampling: 

- n.iter: number of total iterations per chain (including burn-in iterations).
- n.burnin: number of burn-in iterations, i.e. number of iterations to discard at the beginning.
- n.chains: number of Markov chains.
- n.thin: thinning rate, must be a positive integer.

To save computation time, we can run the partitions 
(choose which partition to run, e.g. `partitions=3 or partition=c(1,3,5)`) 
in parallel on separate compute nodes (if you have access to compute clusters). 

Note: we need `R2jags` or `rjags` package to fit TOP models 
in our current version using `JAGS`.
```{r train-TOP-model, eval = FALSE}
library(R2jags)

training_data_partitions <- readRDS('processed_data/ATAC_example_training_data.all.partitions.rds')

TOP_samples_files <- fit_TOP_model(training_data_partitions, 
                                   model.file = '../model/TOP_M5_model_jags_priorVar1.txt',
                                   out.dir = 'TOP_fit',
                                   partitions = 1,5,
                                   n.iter = 10000,
                                   n.burnin = 5000,
                                   n.chains = 3,
                                   n.thin = 10,
                                   transform = 'asinh',
                                   quiet = TRUE,
                                   parallel = TRUE)
```

Combine TOP posterior samples from all partitions and extract the posterior mean of the regression coefficients
----------------------------------------------------------------------------------------------------------------

After the training is done, we can combine the posterior samples from the partitions,
and obtain the posterior mean of the regression coefficients.

Combine TOP posterior samples from the 10 partitions.
```{r combine-TOP-coef, eval = FALSE}
TOP_samples <- combine_TOP_samples(TOP_samples_files)
```

Extract posterior mean coefficients for all three levels.
```{r extract-TOP-mean-coef, eval = FALSE}
TOP_mean_coef <- extract_TOP_mean_coef(TOP_samples, tf_cell_combos)
```

Save the posterior samples and posterior mean coefficients.
```{r save-samples-coef, eval = FALSE}
saveRDS(TOP_samples, file.path(top_model_dir, 'TOP_M5_combined_posterior_samples.rds'))
saveRDS(TOP_mean_coef, file.path(top_model_dir, 'TOP_M5_posterior_mean_coef.rds'))
```

To make predictions for TF occupancy using new DNase- or ATAC-seq data 
using trained model coefficients,
see this [page](predict_TF_occupancy_with_trained_model.html)

