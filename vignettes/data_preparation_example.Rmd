---
title: "An example for input data preparation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{An example for input data preparation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

TOP input data
--------------
TOP requires a data frame as input data for each TF in each cell type. 

The format of the input data frame:

- The first six columns: chr, start, end, site name, strand, motif PWM score.
- The next five columns (if using M5 bins): five MILLIPEDE bins around motif matches. 
- optional: one ChIP column as the response variable. Could be quantitative TF occupancy 
(transformed ChIP-seq read counts) or binary TF binding labels (from ChIP-seq peaks).

Here we give an example for the process of input data preparation for predicting 
CTCF and NRF1 occupancy in K562 cell type.

Major steps
--------------

**Step 1: Find TF motif matches using FIMO software**

To scan for TF motif matches, we use the [FIMO](http://meme-suite.org/doc/fimo.html?man_type=web)
software from the MEME suite.

We use the command line version of FIMO. By default, we used 
with the threshold $p < 1e-5$ and uniform background when training the model. 
You can choose your own background or use FIMO's default threshold $p < 1e-4$ 
(which will result in more motif matches).

Here we show an example for finding motif matches of NRF1. 

FIMO command line: `fimo [options] <motif file> <sequence file>`.
<motif file>: The name of a file containing MEME formatted motifs. 
<sequence file>: The name of a file containing a collection of sequences in FASTA format.

Download the NRF1 motif file `MA0506.1.meme` (in MEME format)
from [JASPAR](https://jaspar.genereg.net/matrix/MA0506.1/). 

Download hg38 fasta file and save as `hg38.fa`.
```{bash download-fasta, eval=FALSE}
wget http://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz
gunzip hg38.fa.gz

```

Save FIMO output in text format (MA0506.1_1e-5.fimo.txt), 
which will be used in the next step. 

```{bash get-motif-matches, eval = FALSE}
topdir=/project2/xinhe/kevinluo/TOP
cd ${topdir}/example
# Find motif matches for CTCF
fimo --text \
     --skip-matched-sequence \
     --verbosity 2 \
     --bgfile --uniform-- \
     --thresh 1e-5 \
     --max-stored-scores 1000000 \
     MA0139.1.meme hg38.fa \
     > MA0139.1_1e-5.fimo.txt
```

**Step 2: Get candidate TF binding sites**

We take motif matches obtained from FIMO (MA0506.1_1e-5.fimo.txt) 
as candidate binding sites, and add 100 bp flanking regions on 
both sides of the motifs, then filter candidate sites by FIMO p-value, and
filter the candidate sites falling in ENCODE blacklist regions. 
We save the candidate sites in a text file (MA0506.1_1e-5.candidate_sites.txt)

Download ENCODE blacklist from [ENCODE portal](https://www.encodeproject.org/annotations/ENCSR636HFF/)

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/get_candidate_sites.R)

```{r get-candidate-sites, eval = TRUE}
#module load R/4.0.4

library(TOP)

blacklist_file <- '../inst/extdata/blacklist.hg38.bed.gz'

CTCF_sites.df <- process_candidate_sites(fimo_file='../inst/extdata/MA0139.1_1e-5.fimo.txt', 
                                         flank=100, 
                                         thresh_pValue=1e-5, 
                                         blacklist_file=blacklist_file,
                                         out_file = '../inst/extdata/MA0139.1_1e-5.candidate_sites.txt')

head(CTCF_sites.df)
```

**Step 3: Count DNase- or ATAC-seq genome-wide cleavage**

We use ATAC-seq reads in K562 cell line from ENCODE (ID: ENCSR868FGK) for example. 

Download ATAC-seq reads. There are three replicates in this study. We found 
modeling replicates do not improve our model, so we typically merge replicates.

For simplicity, here we only use one of the replicates (ENCFF534DCE.bam) as an example,
and rename the file `ENCFF534DCE.bam` as `ATAC.K562.bam`.

We first sort and index the BAM file with DNase-seq or ATAC-seq reads using `samtools`,
and then print the stats of the reads, which will be used later 
when normalizing read counts by library sizes.

```{bash cmd-sort-index-stats-bam, eval = FALSE}
# This bam file is already sorted, so we skip the sorting step. 
# samtools sort ATAC.K562.bam -o ATAC.K562.sorted.bam
samtools index ATAC.K562.bam
samtools idxstats ATAC.K562.bam > ATAC.K562.bam.idxstats.txt
```

Next, we count the DNase- or ATAC-seq counts along the genome, 
and save in Bigwig format. Having these reads counted allows us to efficiently 
extract the read counts around motif match positions for different motifs.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/count_dnase_genome_cuts.R)

We use the `bedtools` and `bedGraphToBigWig` and `bedSort` tools from UCSC.

Use the `fetchChromSizes` script to create the chrom.sizes file which will be needed.
```{bash, eval = FALSE}
fetchChromSizes hg38 > hg38.chrom.sizes
```

```{r count_genome_coverage, eval = FALSE}
# bam_file: input BAM filename.
# chrom_size_file: chrom sizes file.
# outdir: Output directory.
# outname: Output filename prefix.
count_dnase_genome_cuts(bam_file = 'ATAC.K562.bam', chrom_size_file = 'hg38.chrom.sizes', 
                        outdir = "./processed_data/", outname = "CTCF.K562.ATAC")
```

**Step 4: Get DNase- or ATAC-seq count matrices for each motif, then normalize, bin and transform the counts**

Get DNase or ATAC count matrices around candidate sites.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/get_dnase_motif_counts.R)
```{r extract-motif-counts, eval = FALSE}
# sites_file: Filename for candidate sites
# dnase_fwd_count_file: Filename for DNase or ATAC counts in forward strand (Bigwig format)
# dnase_rev_count_file: Filename for DNase or ATAC counts in reverse strand (Bigwig format)
# dnase_fwd_matrix_file: Filename for DNase or ATAC count matrix in forward strand
# dnase_rev_matrix_file: Filename for DNase or ATAC count matrix in reverse strand
dnase_counts <- get_dnase_sites_counts(file_sites, file_dnase_count_fwd, file_dnase_count_rev,
                                       file_dnase_matrix_fwd, file_dnase_matrix_rev)
```

Normalize, bin and transform DNase- or ATAC-seq counts.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/normalize_bin_dnase.R)
```{r normalize-bin-counts, eval = FALSE}
# dnase_counts: DNase or ATAC count matrix
# idxstats_file: The idxstats file generated by samtools
# ref.size: Scale to reference library size 
# (Default: 100 million for DNase-seq and 50 million for ATAC-seq)
# bin.method: MILLIPEDE binning scheme (Default: 'M5').
# transform: asinh or log2 transform of DNase counts.
dnase_bins <- normalize_bin_dnase(dnase_counts, idxstats_file, 
                                  ref.size=1e8, bin.method='M5', transform='asinh')
```

**Step 5: Prepare ChIP-seq data if you want to train your own model (optional)**

Add a column with ChIP counts (from ChIP-seq reads) to the input data frame 
if you want to train the logistic version of the model.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/count_chipseq_coverage.R)
```{r normalize_bin_dnase, eval=FALSE}
# pwm_id: Motif pwm ID
# cell_type: Cell type
# training_metadata: training metadata
# sites_file: Filename for candidate sites
# chrom_size_file: Filename for chromosome sizes
# chip_dir: Directory of ChIP-seq bam files
# outdir: Output directory
# outname: Output filename prefix
# ref.size: ChIP-Seq reference library size (Default: 10 million)
chip_counts <- count_normalize_chip(pwm_id, cell_type, training_metadata,
                                    sites_file, chrom_size_file, chip_dir, 
                                    outdir, outname, ref.size=1e7)
```

Add the binary ChIP labels (from ChIP-seq peaks) to the input data frame 
if you want to train the logistic version of the model

Finally, combine PWM scores, DNase (or ATAC) bins, and ChIP-seq counts or labels.
[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/combine_dnase_chip_data.R)

Snakemake pipeline
-------------------

We provided [Snakemake pipelines](https://github.com/kevinlkx/TOP/tree/main/inst/snakemake) 
to automate the whole process using the above mentioned R scripts. 
The Snakemake is especially helpful if you have many TFs (motifs) in many cell types.

Run `Snakefile_training_ATAC` for ATAC-seq, or `Snakefile_training_DNase` for DNase-seq. 
For more details and instructions about running Snakemake pipelines, 
see [Snakemake tutorial](https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html).
