---
title: 'Train TOP logistic model'
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Train TOP logistic model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = '#>'
)
```

Load TOP R package
---------------------

```{r load-TOP-package, eval=FALSE}
library(TOP)
```


Prepare training data
---------------------

Similar to the steps in [Training TOP quantitative occupancy model](train_TOP_model.html),
We need to prepare and assemble the training data containing all training 
TF x cell type combinations. 

**Step 1: Prepare training data for each TF in each cell type**

Firstly, we need to prepare training data
for each training TF x cell type combination, and 
save the training data files 
(as `.rds` files in the `data_file` column in the table below).

For each TF in each cell type, 
we prepare training data for candidate binding sites:
including: 

- PWM scores of the motif matches
- DNase (or ATAC) counts in MILLIPEDE bins
- *binary ChIP labels* (from ChIP-seq peaks).

You can follow this [procedure](data_preparation.html) to prepare the training data.

**Step 2: Assemble training data for all TF-cell type combinations**

We create a table (data frame) listing all training TF x cell type 
combinations. The table should have three columns:
TF names, cell types, and paths to the training data files, like:

|   tf_name    |   cell_type   |        data_file         |
|:------------:|:-------------:|:------------------------:|
|     CTCF     |     K562      |   CTCF.K562.data.rds     |
|     CTCF     |     A549      |   CTCF.A549.data.rds     |
|     CTCF     |    GM12878    |   CTCF.GM12878.data.rds  |
|     NRF1     |     K562      |   NRF1.K562.data.rds     |
|     MYC      |     K562      |   MYC.K562.data.rds      |
|     ...      |     ...       |   ...                    |


Use the following `assemble_TOP_training_data` function, 
we split the training data randomly into 10 equal partitions, 
so that we could run Gibbs sampling on these partitions in parallel to
reduce the running time. 

We can choose the training chromosomes by specifying the chromosomes in 
`training_chrs`, for example using odd chromosomes as below.
(The chromosome names ("chr...") should match with those in the training data.)

```{r assemble-TOP-logistic-training-data, eval=FALSE}
assembled_training_data <- assemble_training_data(tf_cell_table,
                                                  logistic.model = TRUE, # use logistic model
                                                  chip_colname = 'chip_label', # name of the column with ChIP labels in training data
                                                  training_chrs = paste0('chr', seq(1,21,2)), 
                                                  n.partitions = 10)
```

Save a table listing all TF and cell type combinations. 
This will be used later to extract regression coefficients.
```{r tf-cell-combos, eval=FALSE}
tf_cell_combos <- unique(assembled_training_data[[1]][, c('tf_id', 'cell_id', 'tf_name', 'cell_type')])
```

Fit TOP logistic models using assembled training data
--------------------------------------------------------

Here, we fit TOP logistic models with ChIP-seq binary labels, 
to fit TOP quantitative occupancy models with ChIP-seq read counts, 
please follow this [tutorial](train_TOP_model.htmll).

We fit TOP models using [JAGS](https://mcmc-jags.sourceforge.io), 
and we uses the [R2jags](https://cran.r-project.org/web/packages/R2jags/) 
R package to call JAGS from R.

Please install `R2jags` if you need to train your own TOP models. 
```{r load-R2jags, eval=FALSE}
library(R2jags)
```

We provided the TOP model files in JAGS code 
in the `../model` directory within the package. 
```{r TOP-model-file, eval=FALSE}
model_file <- '../model/TOP_M5_logit_model.jags'
```

The `fit_TOP_model` function below runs Gibbs sampling for each of the 10 partitions 
in parallel (using the `foreach` R package). 

We can set the following parameters for Gibbs sampling: 

- n.iter: number of total iterations per chain (including burn-in iterations).
- n.burnin: number of burn-in iterations, i.e. number of iterations to discard at the beginning.
- n.chains: number of Markov chains.
- n.thin: thinning rate, must be a positive integer.

The following example runs 10000 iterations of Gibbs sampling in total, 
with 2000 burn-ins, 3 Markov chains, thinning rate of 2, 
and save the posterior samples to the `TOP_logistic_fit` directory. 

It could take a long time if we have many TFs and many cell types
in the training data.

```{r fit-TOP-model, eval=FALSE}
TOP_samples_files <- fit_TOP_model(assembled_training_data, 
                                   model.file = model_file,
                                   logistic.model = TRUE,
                                   out.dir = 'TOP_logistic_fit',
                                   partitions = 1:10,
                                   n.iter = 5000, 
                                   n.burnin = 2000,
                                   n.chains = 3,
                                   n.thin = 2,
                                   quiet = TRUE)
```

Alternatively, we can also submit jobs for the partitions
(choose which partition to run, e.g. `partitions=1`) 
in parallel to separate compute nodes on a cluster. 

Combine TOP posterior samples from all partitions and extract the posterior mean of the regression coefficients
----------------------------------------------------------------------------------------------------------------

After we finished Gibbs sampling for all 10 partitions, 
we combine the posterior samples from all the partitions.
```{r combine-TOP-samples, eval=FALSE}
TOP_samples <- combine_TOP_samples(TOP_samples_files)
```

We can extract posterior mean of the coefficients for all three levels.
```{r extract-TOP-mean-coef, eval=FALSE}
TOP_mean_coef <- extract_TOP_mean_coef(TOP_samples, tf_cell_combos)
```

Save posterior samples and posterior mean of the regression coefficients.
```{r save-samples-coef, eval=FALSE}
saveRDS(TOP_samples, 'TOP_logistic_fit/TOP_logistic_M5_combined_posterior_samples.rds')
saveRDS(TOP_mean_coef, 'TOP_logistic_fit/TOP_logistic_M5_posterior_mean_coef.rds')
```

We will provide pre-trained models using ENCODE data
[here](https://users.cs.duke.edu/~amink/software/).

To make predictions for TF occupancy using new DNase- or ATAC-seq data 
using trained model coefficients,
see this [page](predict_TF_occupancy_with_trained_model.html)


