---
title: "Prepare input data"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prepare input data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

We provide functions, scripts and Snakemake pipelines to prepare input data. 

Input format
--------------
TOP requires a data frame as input data for each TF in each cell type. 

The format of the input data frame:

  - The first six columns: chr, start, end, site name, strand, motif PWM score.
  - The next five columns (if using M5 bins): five MILLIPEDE bins around motif matches. 
  - optional: one ChIP column as the response variable. Could be quantitative TF occupancy 
  (transformed ChIP-seq read counts) or binary TF binding labels (from ChIP-seq peaks).

We provided functions and scripts to generate the input data frame. 
You are also welcome to use your own scripts.

Load TOP R package
---------------------
```{r load-TOP-package, eval = FALSE}
library(TOP)
```

Major steps
--------------

**Step 1: Find TF motif matches using FIMO software**

To scan for TF motif matches, we recommend the FIMO software from the MEME suite:

You can follow the instructions from [FIMO](http://meme-suite.org/doc/fimo.html?man_type=web).

We need the FIMO output file in text format (fimo.txt) in the next step. 

We use the command line version of FIMO. By default, we used 
with the threshold $p < 1e-5$ and uniform background when training the model. 

You can choose your own background or use FIMO's default threshold $p < 1e-4$ 
(which will result in more motif matches).

Example FIMO command and settings:
```{r get-motif-matches, eval = FALSE}
# outdir: the output directory
# pwm: motif PWM file
# ref_genome: reference genome file
fimo --text --skip-matched-sequence --verbosity 2 \
  --bgfile --uniform-- \
  --thresh 1e-5 --max-stored-scores 1000000 \
  --oc outdir \
  pwm ref_genome
```

**Step 2: Get candidate TF binding sites**

We take motif matches obtained from FIMO as candidate binding sites, 
and add 100bp flanking regions on both sides of the motifs.
Then filter the candidate sites by ENCODE blacklist regions and/or 
with mapability threshold. 

Example function to get candidate binding sites from FIMO result.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/get_candidate_sites.R)
```{r get-candidate-sites, eval = FALSE}
# fimo_file: Filename of FIMO result.
# sites_file: Filename of candidate sites.
# flank: Flanking region (bp) around motif matches (default: 100)
# thresh_pValue: FIMO p-value threshold.
# blacklist_file Filename of the blacklist regions
sites.df <- process_candidate_sites(fimo_file, sites_file, 
                                    flank=100, thresh_pValue=1e-5, 
                                    blacklist_file=blacklist_file)

```

**Step 3: Count DNase- or ATAC-seq genome-wide cleavage**

We first sort and index the BAM file with DNase-seq or ATAC-seq reads,
and then print the stats of the reads, which will be used later 
when normalizing read counts by library sizes.

Run samtools commands: 
```{bash cmd-sort-index-stats-bam, eval = FALSE}
samtools sort sample.bam -o sample.sorted.bam
samtools index sample.sorted.bam
samtools idxstats sample.sorted.bam > sample.bam.idxstats.txt
```

Or use this wrapper function:
```{r sort-index-stats-bam-function, eval = FALSE}
# bam_file: input BAM filename.
# outdir: output directory.
bam_sort_index_stats(bam_file, outdir)
```

Next, we count the DNase- or ATAC-seq counts along the genome, 
and save in Bigwig format. Having these reads counted allows us to efficiently 
extract the read counts around motif match positions for different motifs.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/count_dnase_genome_cuts.R)
```{r count_genome_coverage, eval = FALSE}
# bam_file: input BAM filename.
# chrom_size_file: File name of genome sizes by chromosomes.
# outdir: Output directory.
# outname: Output filename prefix.
count_dnase_genome_cuts(bam_file, chrom_size_file, outdir, outname)
```

**Step 4: Get DNase- or ATAC-seq count matrices for each motif, then normalize, bin and transform the counts**

Get DNase or ATAC count matrices around candidate sites.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/get_dnase_motif_counts.R)
```{r extract-motif-counts, eval = FALSE}
# sites_file: Filename for candidate sites
# dnase_fwd_count_file: Filename for DNase or ATAC counts in forward strand (Bigwig format)
# dnase_rev_count_file: Filename for DNase or ATAC counts in reverse strand (Bigwig format)
# dnase_fwd_matrix_file: Filename for DNase or ATAC count matrix in forward strand
# dnase_rev_matrix_file: Filename for DNase or ATAC count matrix in reverse strand
dnase_counts <- get_dnase_sites_counts(file_sites, file_dnase_count_fwd, file_dnase_count_rev,
                       file_dnase_matrix_fwd, file_dnase_matrix_rev)
```

Normalize, bin and transform DNase- or ATAC-seq counts.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/normalize_bin_dnase.R)
```{r normalize-bin-counts, eval = FALSE}
# dnase_counts: DNase or ATAC count matrix
# idxstats_file: The idxstats file generated by samtools
# ref.size: Scale to reference library size 
# (Default: 100 million for DNase-seq and 50 million for ATAC-seq)
# bin.method: MILLIPEDE binning scheme (Default: 'M5').
# transform: asinh or log2 transform of DNase counts.
dnase_bins <- normalize_bin_dnase(dnase_counts, idxstats_file, 
                                  ref.size=1e8, bin.method='M5', transform='asinh')
```

**Step 5: Prepare ChIP-seq data if you want to train your own model (optional)**

Add a column with ChIP counts (from ChIP-seq reads) to the input data frame 
if you want to train the logistic version of the model.

[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/count_chipseq_coverage.R)
```{r normalize_bin_dnase, eval=FALSE}
# pwm_id: Motif pwm ID
# cell_type: Cell type
# training_metadata: training metadata
# sites_file: Filename for candidate sites
# chrom_size_file: Filename for chromosome sizes
# chip_dir: Directory of ChIP-seq bam files
# outdir: Output directory
# outname: Output filename prefix
# ref.size: ChIP-Seq reference library size (Default: 10 million)
chip_counts <- count_normalize_chip(pwm_id, cell_type, training_metadata,
                                    sites_file, chrom_size_file, chip_dir, 
                                    outdir, outname, ref.size=1e7)
```

Add the binary ChIP labels (from ChIP-seq peaks) to the input data frame 
if you want to train the logistic version of the model

Finally, combine PWM scores, DNase (or ATAC) bins, and ChIP-seq counts or labels.
[Example script](https://github.com/kevinlkx/TOP/tree/main/inst/scripts/combine_dnase_chip_data.R)

Snakemake pipeline
-------------------

We provided [Snakemake pipelines](https://github.com/kevinlkx/TOP/tree/main/inst/snakemake) 
to automate the whole process using the above mentioned R scripts. 
The Snakemake is especially helpful if you have many TFs (motifs) in many cell types.

Run `Snakefile_training_ATAC` for ATAC-seq, or `Snakefile_training_DNase` for DNase-seq. 
For more details and instructions about running Snakemake pipelines, 
see [Snakemake tutorial](https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html).
