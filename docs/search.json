[{"path":"https://kevinlkx.github.io/TOP/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2020 Kaixuan Luo Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://kevinlkx.github.io/TOP/articles/data_preparation.html","id":"top-input-data","dir":"Articles","previous_headings":"","what":"TOP input data","title":"Prepare input data","text":"TOP requires data frame input data TF cell type. format input data frame: first six columns: chr, start, end, site name, strand, motif PWM score. next five columns (using M5 bins): five MILLIPEDE bins around motif matches. optional: one ChIP column response variable. quantitative TF occupancy (asinh transformed ChIP-seq read counts) binary TF binding labels (ChIP-seq peaks). give example preparing input data TOP predict CTCF occupancy K562 cell type.","code":""},{"path":"https://kevinlkx.github.io/TOP/articles/data_preparation.html","id":"major-steps","dir":"Articles","previous_headings":"","what":"Major steps","title":"Prepare input data","text":"Step 1: Find TF motif matches using FIMO software scan TF motif matches, use FIMO software MEME suite. use command line version FIMO. default, used threshold p-value < 1e-5 uniform background nucleotide frequency. can use FIMO’s default threshold p-value < 1e-4 (result motif matches), use background nucleotide frequency. FIMO command line: fimo [options] <motif file> <sequence file>. motif file: name file containing MEME formatted motifs. sequence file: name file containing collection sequences FASTA format. Download CTCF motif file MA0139.1.meme (MEME format) JASPAR. Download hg38 fasta file save hg38.fa. Generate chrom.sizes file needed later. Save FIMO output text format (MA0139.1_1e-5.fimo.txt), used next step. Step 2: Get candidate TF binding sites take motif matches obtained FIMO (MA0139.1_1e-5.fimo.txt) candidate binding sites, add 100 bp flanking regions sides motifs, filter candidate sites FIMO p-value, filter candidate sites falling ENCODE blacklist regions. save candidate sites text file (MA0139.1_1e-5.candidate_sites.txt) Download ENCODE blacklist ENCODE portal Load TOP R package Step 3: Count DNase- ATAC-seq genome-wide cleavage use ATAC-seq reads K562 cell line ENCODE (ID: ENCSR868FGK) example. three replicates study. practice, merge replicate samples. use one replicates (ENCFF534DCE.bam) example demo process, rename file K562.ATAC.bam. first sort index BAM file using samtools, print stats reads, used later normalizing read counts library sizes. Next, count cleavages along genome, save Bigwig format. step takes time needs done , allows us efficiently extract read counts around candidate sites many different motifs. need bedtools bedGraphToBigWig UCSC step. Step 4: Get DNase- ATAC-seq count matrices motif, normalize, bin transform counts Get count matrices around candidate sites. need bwtool step. Normalize, bin transform counts. Make data frame PWM scores, ATAC (DNase) bins. can apply TOP model data frame make predictions. Step 5: Prepare ChIP-seq data (optional want train model) Download CTCF K562 ChIP-seq bam files (ENCODE ID: ENCSR000EGM, two replicates: ENCFF172KOJ ENCFF265ZSP). sort index BAM files print stats reads using samtools. Count ChIP-seq reads around candidate sites (merge ChIP-seq replicates), normalize (scale) reference library size (10 million). Combine PWM scores, ATAC (DNase) bins, ChIP-seq counts data frame. Replace ChIP-seq counts binary ChIP labels (ChIP-seq peaks) want train TOP logistic version predict TF binding probability.","code":"wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/analysisSet/hg38.analysisSet.fa.gz gunzip hg38.analysisSet.fa.gz mv hg38.analysisSet.fa hg38.fa samtools faidx hg38.fa cut -f 1,2 hg38.fa.fai > hg38.chrom.sizes # Find motif matches for CTCF fimo --text \\      --skip-matched-sequence \\      --verbosity 2 \\      --bgfile --uniform-- \\      --thresh 1e-5 \\      --max-stored-scores 1000000 \\      MA0139.1.meme hg38.fa \\      > MA0139.1_1e-5.fimo.txt library(TOP) sites.df <- process_candidate_sites(fimo_file='MA0139.1_1e-5.fimo.txt',                                      flank=100,                                      thresh_pValue=1e-5,                                      blacklist_file='blacklist.hg38.bed.gz',                                     out_file = 'processed_data/MA0139.1_1e-5.candidate_sites.txt') # rename the bam file mv ENCFF534DCE.bam K562.ATAC.bam  # This bam file is already sorted, so we skip the sorting step.  samtools index K562.ATAC.bam samtools idxstats K562.ATAC.bam > K562.ATAC.bam.idxstats.txt # bam_file: input BAM filename. # chrom_size_file: chrom sizes file. # outdir: Save bigWig files of genome counts in this directory. count_genome_cuts(bam_file = 'K562.ATAC.bam',                    chrom_size_file = 'hg38.chrom.sizes',                    outdir = \"processed_data/\") # sites_file: Candidate sites filename. # genomecount_dir: Genome counts directory. # genomecount_name: Genome counts prefix. count_matrix <- get_sites_counts(sites_file='processed_data/MA0139.1_1e-5.candidate_sites.txt',                                   genomecount_dir='./processed_data/',                                  genomecount_name='K562.ATAC') # count_matrix: ATAC (or DNase) count matrix # idxstats_file: The idxstats file generated by samtools # ref.size: Scale to reference library size  # (default: 50 million for ATAC-seq, 100 million for DNase-seq) # bin.method: MILLIPEDE binning scheme (default: 'M5'). # transform: asinh transform of the counts. bins.df <- normalize_bin_transform_counts(count_matrix,                                            idxstats_file='K562.ATAC.bam.idxstats.txt',                                            ref.size=5e7,                                           bin.method='M5',                                           transform='asinh') combined_data.df <- data.frame(sites.df, bins.df) colnames(combined_data.df) <- c('chr','start','end','name','pwm.score','strand','p.value', paste0('bin', 1:ncol(bins.df)))  saveRDS(combined_data.df, 'processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.combined.data.rds') combined_data.df <- readRDS('../inst/example/processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.combined.data.rds') head(combined_data.df, 3) #>    chr start   end  name pwm.score strand  p.value      bin1      bin2 bin3 #> 1 chr1 11122 11341 site1   22.4839      - 9.17e-09 0.2232134 0.0000000    0 #> 2 chr1 11180 11399 site2   20.7581      - 5.22e-08 0.0000000 0.2232134    0 #> 3 chr1 24681 24900 site3   16.5645      - 1.31e-06 0.0000000 0.0000000    0 #>   bin4 bin5 #> 1    0    0 #> 2    0    0 #> 3    0    0 # rename the bam files mv ENCFF172KOJ.bam CTCF.K562.ChIPseq.rep1.bam mv ENCFF265ZSP.bam CTCF.K562.ChIPseq.rep2.bam  # The bam files are already sorted, so we skip the sorting step.  samtools index CTCF.K562.ChIPseq.rep1.bam samtools idxstats CTCF.K562.ChIPseq.rep1.bam > CTCF.K562.ChIPseq.rep1.bam.idxstats.txt  samtools index CTCF.K562.ChIPseq.rep2.bam samtools idxstats CTCF.K562.ChIPseq.rep2.bam > CTCF.K562.ChIPseq.rep2.bam.idxstats.txt # ref.size: ChIP-Seq reference library size (default: 10 million) sites_chip.df <- count_normalize_chip(sites_file = 'processed_data/MA0139.1_1e-5.candidate_sites.txt',                                        chip_bam_files = c('CTCF.K562.ChIPseq.rep1.bam', 'CTCF.K562.ChIPseq.rep2.bam'),                                       chrom_size_file = 'hg38.chrom.sizes',                                        ref.size = 1e7) combined_data.df <- data.frame(sites.df, bins.df, sites_chip.df$chip) colnames(combined_data.df) <- c('chr','start','end','name','pwm.score','strand','p.value', paste0('bin', 1:ncol(bins.df)), 'chip') saveRDS(combined_data.df, 'processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.ChIP.combined.data.rds') combined_data.df <- readRDS('../inst/example/processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.ChIP.combined.data.rds') head(combined_data.df, 3) #>    chr start   end  name pwm.score strand  p.value      bin1      bin2 bin3 #> 1 chr1 11122 11341 site1   22.4839      - 9.17e-09 0.2232134 0.0000000    0 #> 2 chr1 11180 11399 site2   20.7581      - 5.22e-08 0.0000000 0.2232134    0 #> 3 chr1 24681 24900 site3   16.5645      - 1.31e-06 0.0000000 0.0000000    0 #>   bin4 bin5 chip #> 1    0    0    0 #> 2    0    0    0 #> 3    0    0    0"},{"path":"https://kevinlkx.github.io/TOP/articles/data_preparation.html","id":"snakemake-pipeline","dir":"Articles","previous_headings":"","what":"Snakemake pipeline","title":"Prepare input data","text":"provided Snakemake pipelines automate whole process using mentioned R scripts. Snakemake especially helpful many TFs (motifs) many cell types. Run Snakefile_training_ATAC ATAC-seq, Snakefile_training_DNase DNase-seq. details instructions running Snakemake pipelines, see Snakemake tutorial.","code":""},{"path":"https://kevinlkx.github.io/TOP/articles/predict_TF_occupancy_with_trained_model.html","id":"load-top-r-package","dir":"Articles","previous_headings":"","what":"Load TOP R package","title":"Predict TF occupancy using trained TOP model","text":"","code":"library(TOP) library(ggplot2) library(cowplot)"},{"path":"https://kevinlkx.github.io/TOP/articles/predict_TF_occupancy_with_trained_model.html","id":"input-data","dir":"Articles","previous_headings":"","what":"Input data","title":"Predict TF occupancy using trained TOP model","text":"input data data frame, including six columns. Columns left right PWM scores 5 DNase (ATAC) bins. can follow page prepare input data.","code":""},{"path":"https://kevinlkx.github.io/TOP/articles/predict_TF_occupancy_with_trained_model.html","id":"download-pre-trained-top-models","dir":"Articles","previous_headings":"","what":"Download pre-trained TOP models","title":"Predict TF occupancy using trained TOP model","text":"provide pre-trained models using ENCODE data . Load trained TOP model regression coefficients TF- cell-type- specific model (bottom level) regression coefficients TF-specific cell-type-generic model (middle level) regression coefficients TF-generic model (top level) regression coefficients","code":"TOP_mean_coef <- readRDS('../inst/trained_model_coef/ATAC/TOP_M5_posterior_mean_coef.rds') summary(TOP_mean_coef) #>        Length Class  Mode    #> top       7   -none- numeric #> middle  455   -none- numeric #> bottom 1414   -none- numeric head(TOP_mean_coef$bottom, 3) #>                Intercept        PWM       Bin1      Bin2         Bin3      Bin4 #> ATF1.K562     -1.7690767 0.21758724 0.10161658 0.4209041 -0.416652011 0.4456277 #> BACH1.GM12878  0.3781784 0.04573713 0.15204184 0.2209277 -0.004968313 0.2045168 #> BACH1.K562    -0.2657850 0.07925225 0.07578085 0.2991205 -0.012988483 0.2997322 #>                     Bin5 #> ATF1.K562     0.10719844 #> BACH1.GM12878 0.14301801 #> BACH1.K562    0.02633572 head(TOP_mean_coef$middle, 3) #>         Intercept        PWM       Bin1      Bin2        Bin3      Bin4 #> ATF1  -0.97200352 0.14219233 0.09213494 0.3566015 -0.20341658 0.3664693 #> BACH1 -0.02804098 0.06225104 0.10576962 0.2685970 -0.01240542 0.2649561 #> BATF  -0.30109722 0.07463380 0.10686063 0.3500711 -0.04610244 0.3532608 #>             Bin5 #> ATF1  0.09053287 #> BACH1 0.08219806 #> BATF  0.10103080 head(TOP_mean_coef$top) #>   Intercept         PWM        Bin1        Bin2        Bin3        Bin4  #> -0.20701728  0.07683929  0.07946925  0.27850429  0.00873352  0.28956758"},{"path":"https://kevinlkx.github.io/TOP/articles/predict_TF_occupancy_with_trained_model.html","id":"predict-tf-occupancy-using-trained-top-model","dir":"Articles","previous_headings":"","what":"Predict TF occupancy using trained TOP model","title":"Predict TF occupancy using trained TOP model","text":"Load data Predict CTCF occupancy K562 cell type using bottom level regression coefficients CTCF K562 Plot predicted occupancy vs. measured occupancy","code":"data <- readRDS('../inst/example/processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.combined.data.rds') head(data,3) #>    chr start   end  name pwm.score strand  p.value      bin1      bin2 bin3 #> 1 chr1 11122 11341 site1   22.4839      - 9.17e-09 0.2232134 0.0000000    0 #> 2 chr1 11180 11399 site2   20.7581      - 5.22e-08 0.0000000 0.2232134    0 #> 3 chr1 24681 24900 site3   16.5645      - 1.31e-06 0.0000000 0.0000000    0 #>   bin4 bin5 #> 1    0    0 #> 2    0    0 #> 3    0    0 # Choose trained regression coefficients (bottom level) for CTCF in K562 model_coef <- TOP_mean_coef$bottom['CTCF.K562',]  data$predicted.occupancy <- predict_TOP(data,                                          model_coef,                                          posterior.option = 'mean',                                          transform = 'asinh') #> Predicting TF occupancy using TOP posterior mean coefficients... #> Select features: pwm.score bin1 bin2 bin3 bin4 bin5 data_chip <- readRDS('../inst/example/processed_data/CTCF_MA0139.1_1e-5.K562.ATAC.M5.ChIP.combined.data.rds')  scatterplot_predictions(x = asinh(data_chip$chip),                         y = asinh(data$predicted.occupancy),                         title = 'Predicting CTCF occupancy in K562 cell',                         xlab = 'asinh(measured occupancy)',                         ylab = 'asinh(predicted occupancy)',                         xlim = c(0,8),                         ylim = c(0,8))"},{"path":"https://kevinlkx.github.io/TOP/articles/predict_TF_occupancy_with_trained_model.html","id":"predict-tf-binding-probability-using-trained-top-logistic-model","dir":"Articles","previous_headings":"","what":"Predict TF binding probability using trained TOP logistic model","title":"Predict TF occupancy using trained TOP model","text":"Load trained TOP model regression coefficients","code":"TOP_logistic_mean_coef <- readRDS('../inst/trained_model_coef/ATAC/TOP_logistic_M5_posterior_mean_coef.rds') summary(TOP_logistic_mean_coef) #>        Length Class  Mode    #> top       7   -none- numeric #> middle  455   -none- numeric #> bottom 1400   -none- numeric # Choose trained regression coefficients (bottom level) for CTCF in K562 model_coef <- TOP_logistic_mean_coef$bottom['CTCF.K562',]  data$predicted.prob <- predict_TOP(data,                                     model_coef,                                     logistic.model = TRUE,                                     posterior.option = 'mean') #> Select features: pwm.score bin1 bin2 bin3 bin4 bin5  #> Predicting TF binding probability using TOP logistic model posterior mean coefficients... head(data, 3) #>    chr start   end  name pwm.score strand  p.value      bin1      bin2 bin3 #> 1 chr1 11122 11341 site1   22.4839      - 9.17e-09 0.2232134 0.0000000    0 #> 2 chr1 11180 11399 site2   20.7581      - 5.22e-08 0.0000000 0.2232134    0 #> 3 chr1 24681 24900 site3   16.5645      - 1.31e-06 0.0000000 0.0000000    0 #>   bin4 bin5 predicted.occupancy predicted.prob #> 1    0    0           1.6817220     0.05973761 #> 2    0    0           1.8754262     0.06533921 #> 3    0    0           0.9999525     0.01410157"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_logistic_model.html","id":"load-top-r-package","dir":"Articles","previous_headings":"","what":"Load TOP R package","title":"Train TOP logistic model","text":"","code":"library(TOP)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_logistic_model.html","id":"prepare-training-data","dir":"Articles","previous_headings":"","what":"Prepare training data","title":"Train TOP logistic model","text":"Step 1: Prepare training data TF cell type TF cell type, prepare training data candidate binding sites: including: PWM scores, DNase (ATAC) bins, binary ChIP labels (ChIP-seq peaks). can follow page prepare training data. create data frame listing TF names, cell types, links training data files. Step 2: Assemble training data TF-cell type combinations Assemble training datasets training TF-cell type combinations, split training data 10 partitions.","code":"all_training_data <- assemble_TOP_training_data(tf_cell_table = './tf_cell_table.txt',                                                 training_data_dir = './',                                                  training_data_name = 'TOP_training_data',                                                 logistic.model = TRUE,                                                 chip_colname = 'chip_label',                                                 training_chrs = paste0('chr', seq(1,21,2)),                                                 n.partitions = 10)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_logistic_model.html","id":"train-top-logistic-models-using-assembled-training-data","dir":"Articles","previous_headings":"","what":"Train TOP logistic models using assembled training data","title":"Train TOP logistic model","text":"Train TOP logistic model partition separately, save posterior samples. can set following parameters Gibbs sampling: n.iter: number total iterations per chain (including burn-iterations). n.burnin: number burn-iterations, .e. number iterations discard beginning. n.chains: number Markov chains. n.thin: thinning rate, must positive integer. save computation time, can run partitions (choose partition run, e.g. partitions=3 partition=c(1,3,5)) parallel separate compute nodes (access compute clusters).","code":"train_TOP_model(model_file = '../model/TOP_M5_logit_model_jags_priorVar1.txt',                 training_data_dir = './',                  training_data_name = 'TOP_training_data',                 logistic.model = TRUE,                 out_dir = 'TOP_output',                 partitions=c(1:10),                 n.iter=10000,                 n.burnin=5000,                 n.chains=3,                 n.thin=10)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_logistic_model.html","id":"combine-top-posterior-samples-from-all-partitions-and-extract-the-posterior-mean-of-the-regression-coefficients","dir":"Articles","previous_headings":"","what":"Combine TOP posterior samples from all partitions and extract the posterior mean of the regression coefficients","title":"Train TOP logistic model","text":"training done, can combine posterior samples partitions, obtain posterior mean regression coefficients. Combine TOP posterior samples 10 partitions Extract posterior mean coefficients three levels Save posterior samples posterior mean regression coefficients provide pre-trained models using ENCODE data . make predictions TF occupancy using new DNase- ATAC-seq data, see page","code":"TOP_samples_files <- file.path('TOP_output',                                 paste0('TOP_logistic_M5_partition', 1:10, '.posterior_samples.rds')) TOP_samples <- combine_TOP_samples(TOP_samples_files) tf_cell_combos <- read.table(tf_cell_combo_file, header=TRUE, sep='\\t', stringsAsFactors = FALSE) tf_cell_combos <- unique(tf_cell_combos[, c('tf_id', 'cell_id', 'tf_name', 'cell_type')]) TOP_mean_coef <- extract_TOP_mean_coef(TOP_samples, tf_cell_combos) saveRDS(TOP_samples, 'TOP_output/TOP_logistic_M5_combined_posterior_samples.rds') saveRDS(TOP_mean_coef, 'TOP_output/TOP_logistic_M5_posterior_mean_coef.rds')"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_model.html","id":"load-top-r-package","dir":"Articles","previous_headings":"","what":"Load TOP R package","title":"Train TOP model","text":"","code":"library(TOP)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_model.html","id":"prepare-training-data","dir":"Articles","previous_headings":"","what":"Prepare training data","title":"Train TOP model","text":"Step 1: Prepare training data TF cell type TF cell type, prepare training data candidate binding sites: including: PWM scores, DNase (ATAC) bins, measured TF occupancy (ChIP-seq data). can follow page prepare training data. create data frame listing TF names, cell types, links training data files. Step 2: Assemble training data TF-cell type combinations Assemble training datasets training TF-cell type combinations, split training data 10 partitions. Select odd chromosomes training set.","code":"all_training_data <- assemble_TOP_training_data(tf_cell_table = './tf_cell_table.txt',                                                 training_data_dir = './',                                                  training_data_name = 'TOP_training_data',                                                 chip_colname = 'chip',                                                 training_chrs = paste0('chr', seq(1,21,2)),                                                  n.partitions = 10)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_model.html","id":"train-top-models-using-assembled-training-data","dir":"Articles","previous_headings":"","what":"Train TOP models using assembled training data","title":"Train TOP model","text":"Fit TOP model partition separately, save posterior samples. can set following parameters Gibbs sampling: n.iter: number total iterations per chain (including burn-iterations). n.burnin: number burn-iterations, .e. number iterations discard beginning. n.chains: number Markov chains. n.thin: thinning rate, must positive integer. save computation time, can run partitions (choose partition run, e.g. partitions=3 partition=c(1,3,5)) parallel separate compute nodes (access compute clusters).","code":"train_TOP_model(model_file = '../model/TOP_M5_model_jags_priorVar1.txt',                 training_data_dir = './',                  training_data_name = 'TOP_training_data',                 out_dir = './TOP_samples/',                 partitions = c(1:10),                 n.iter = 10000,                 n.burnin = 5000,                 n.chains = 3,                 n.thin = 10)"},{"path":"https://kevinlkx.github.io/TOP/articles/train_TOP_model.html","id":"combine-top-posterior-samples-from-all-partitions-and-extract-the-posterior-mean-of-the-regression-coefficients","dir":"Articles","previous_headings":"","what":"Combine TOP posterior samples from all partitions and extract the posterior mean of the regression coefficients","title":"Train TOP model","text":"training done, can combine posterior samples partitions, obtain posterior mean regression coefficients. Combine TOP posterior samples 10 partitions. Extract posterior mean coefficients three levels. Save posterior samples posterior mean coefficients. provide pre-trained models using ENCODE data .. make predictions TF occupancy using new DNase- ATAC-seq data, see page","code":"top_model_dir <- './TOP_samples/' TOP_samples_files <- file.path(top_model_dir, paste0('TOP_M5_partition', 1:10, '.posterior_samples.rds')) TOP_samples <- combine_TOP_samples(TOP_samples_files) tf_cell_combos <- read.table(tf_cell_combo_file, header=TRUE, sep='\\t', stringsAsFactors = FALSE) tf_cell_combos <- unique(tf_cell_combos[, c('tf_id', 'cell_id', 'tf_name', 'cell_type')]) TOP_mean_coef <- extract_TOP_mean_coef(TOP_samples, tf_cell_combos) saveRDS(TOP_samples, file.path(top_model_dir, 'TOP_M5_combined_posterior_samples.rds')) saveRDS(TOP_mean_coef, file.path(top_model_dir, 'TOP_M5_posterior_mean_coef.rds'))"},{"path":"https://kevinlkx.github.io/TOP/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kaixuan Luo. Author, maintainer. Jianling Zhong. Author. Alex Hartemink. Author, copyright holder.","code":""},{"path":"https://kevinlkx.github.io/TOP/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Luo K, Zhong J, Hartemink (2021). TOP: Transcription factor Occupancy Profiler (TOP). R package version 0.0.0.9000, https://github.com/kevinlkx/TOP.","code":"@Manual{,   title = {TOP: Transcription factor Occupancy Profiler (TOP)},   author = {Kaixuan Luo and Jianling Zhong and Alex Hartemink},   year = {2021},   note = {R package version 0.0.0.9000},   url = {https://github.com/kevinlkx/TOP}, }"},{"path":"https://kevinlkx.github.io/TOP/index.html","id":"transcription-factor-occupancy-profiler-top","dir":"","previous_headings":"","what":"Transcription factor Occupancy Profiler (TOP)","title":"Transcription factor Occupancy Profiler (TOP)","text":"Transcription factor Occupancy Profiler (TOP) fits Bayesian hierarchical model using transcription factor (TF) motifs, DNase- ATAC-seq data, well ChIP-seq data (required training) multiple TFs across multiple cell types. can used predict quantitative occupancy binding probability many TFs using data single DNase- ATAC-seq experiment. Thus, allows efficient profiling quantitative TF occupancy landscapes across multiple cell types conditions using DNase- ATAC-seq experiments.","code":""},{"path":"https://kevinlkx.github.io/TOP/index.html","id":"top-r-package-website","dir":"","previous_headings":"","what":"TOP R package website","title":"Transcription factor Occupancy Profiler (TOP)","text":"Install R package","code":"install.packages(\"devtools\") library(devtools) devtools::install_github(\"kevinlkx/TOP\")  library(TOP)"},{"path":"https://kevinlkx.github.io/TOP/index.html","id":"reference","dir":"","previous_headings":"","what":"Reference","title":"Transcription factor Occupancy Profiler (TOP)","text":"Luo, K., Zhong, J., Safi, ., Hong, L., Tewari, ., Song, L., Reddy, T., Ma, L., Crawford, G., & Hartemink, . (2020) “Quantitative occupancy myriad transcription factors one DNase experiment enables efficient comparisons across conditions.” bioRxiv, bioRxiv:2020.06.28.171587.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_TOP_training_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into 10 partitions — assemble_TOP_training_data","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into 10 partitions — assemble_TOP_training_data","text":"Assemble TOP training data TF x cell type combos, split training data 10 partitions","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_TOP_training_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into 10 partitions — assemble_TOP_training_data","text":"","code":"assemble_TOP_training_data(   tf_cell_table,   training_data_dir = \"./\",   training_data_name = \"TOP_training_data\",   logistic.model = FALSE,   chip_colname = \"chip\",   training_chrs = paste0(\"chr\", seq(1, 21, 2)),   n.partitions = 10,   max.sites = 50000,   seed = 1 )"},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_TOP_training_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into 10 partitions — assemble_TOP_training_data","text":"tf_cell_table data frame TF name, cell type, links training data files. training_data_dir Directory saving training data training_data_name Prefix training data file names logistic.model TRUE, use logistic version model chip_colname column name ChIP data combined data. training_chrs Chromosomes used training model. n.partitions split data partitions (default = 10) run Gibbs sampling parallel. max.sites Max number candidate sites partition. seed seed used sampling sites.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_partition_training_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into partitions\n#' — assemble_partition_training_data","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into partitions\n#' — assemble_partition_training_data","text":"Assemble TOP training data TF x cell type combos, split training data partitions #'","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_partition_training_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into partitions\n#' — assemble_partition_training_data","text":"","code":"assemble_partition_training_data(   tf_cell_table,   logistic.model = FALSE,   chip_colname = \"chip\",   training_chrs = paste0(\"chr\", seq(1, 21, 2)),   n.partitions = 10,   part,   max.sites = 10000,   seed = 1 )"},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_partition_training_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into partitions\n#' — assemble_partition_training_data","text":"tf_cell_table data frame TF name, cell type, links training data files. logistic.model TRUE, use logistic version model chip_colname column name ChIP data combined data. training_chrs Chromosomes used training model. n.partitions split data partitions (default = 10) run Gibbs sampling parallel. part partition use training model max.sites Max number candidate sites partition. seed seed used sampling sites.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/assemble_partition_training_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Assemble TOP training data for all TF x cell type combos,\nthen split training data into partitions\n#' — assemble_partition_training_data","text":"Returns data frame training data TFs cell type combos.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/bam_sort_index_stats.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort and index the BAM file, and then retrieve and print stats in the index file. — bam_sort_index_stats","title":"Sort and index the BAM file, and then retrieve and print stats in the index file. — bam_sort_index_stats","text":"Sort index BAM file, retrieve print stats index file.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/bam_sort_index_stats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort and index the BAM file, and then retrieve and print stats in the index file. — bam_sort_index_stats","text":"","code":"bam_sort_index_stats(   bam_file,   outdir = NA,   sort = TRUE,   stats = TRUE,   samtools_path = \"samtools\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/bam_sort_index_stats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort and index the BAM file, and then retrieve and print stats in the index file. — bam_sort_index_stats","text":"bam_file Input BAM file. outdir Output directory. sort logical. TRUE, sort (index) BAM file. stats logical. TRUE, retrieve print stats index file. samtools_path Path samtools executable.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/bin_transform_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Binning and transform count matrix — bin_transform_counts","title":"Binning and transform count matrix — bin_transform_counts","text":"Binning DNase (ATAC) count matrix using MILLIPEDE binning take asinh (log2) transform","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/bin_transform_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binning and transform count matrix — bin_transform_counts","text":"","code":"bin_transform_counts(   counts,   bin.method = c(\"M5\", \"M1\", \"M2\", \"M3\", \"M12\", \"M24\"),   transform = c(\"asinh\", \"log2\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/bin_transform_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Binning and transform count matrix — bin_transform_counts","text":"counts DNase (ATAC) count matrix bin.method MILLIPEDE binning scheme (Default: 'M5'). transform asinh log2 transform","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/combine_TOP_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine and take the average of TOP posterior samples from all partitions — combine_TOP_samples","title":"Combine and take the average of TOP posterior samples from all partitions — combine_TOP_samples","text":"Combine take average TOP posterior samples partitions","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/combine_TOP_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine and take the average of TOP posterior samples from all partitions — combine_TOP_samples","text":"","code":"combine_TOP_samples(TOP_samples_files, thin = 1, n.samples = 1000)"},{"path":"https://kevinlkx.github.io/TOP/reference/combine_TOP_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine and take the average of TOP posterior samples from all partitions — combine_TOP_samples","text":"TOP_samples_files file names posterior samples partitions thin thinning rate extract posterior samples, must positive integer. n.samples Randomly choose n.samples posterior samples, number posterior samples greater n.samples","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/count_genome_cuts.html","id":null,"dir":"Reference","previous_headings":"","what":"Count DNase-seq or ATAC-seq cleavage for a given genome. — count_genome_cuts","title":"Count DNase-seq or ATAC-seq cleavage for a given genome. — count_genome_cuts","text":"Count DNase-seq ATAC-seq cleavage given genome.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/count_genome_cuts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count DNase-seq or ATAC-seq cleavage for a given genome. — count_genome_cuts","text":"","code":"count_genome_cuts(   bam_file,   chrom_size_file,   outdir,   outname,   bedtools_path = \"bedtools\",   bedGraphToBigWig_path = \"bedGraphToBigWig\",   bedSort_path = \"bedSort\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/count_genome_cuts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count DNase-seq or ATAC-seq cleavage for a given genome. — count_genome_cuts","text":"bam_file Sorted BAM file. chrom_size_file File name genome sizes chromosomes. outdir Output directory. outname Output prefix. bedtools_path Path bedtools executable. bedGraphToBigWig_path Path UCSC bedGraphToBigWig executable. bedSort_path Path UCSC bedSort executable.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/count_normalize_chip.html","id":null,"dir":"Reference","previous_headings":"","what":"Count and normalize ChIP-seq read coverage — count_normalize_chip","title":"Count and normalize ChIP-seq read coverage — count_normalize_chip","text":"Count normalize ChIP-seq read coverage","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/count_normalize_chip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Count and normalize ChIP-seq read coverage — count_normalize_chip","text":"","code":"count_normalize_chip(   sites_file,   chip_bam_files,   chip_idxstats_files,   chrom_size_file,   ref.size = 1e+07,   transform = c(\"none\", \"asinh\", \"log2\", \"sqrt\"),   bedtools_path = \"bedtools\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/count_normalize_chip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Count and normalize ChIP-seq read coverage — count_normalize_chip","text":"sites_file Candidate sites file chip_bam_files ChIP-seq bam files chip_idxstats_files ChIP-seq idxstats files. default, use corresponding '.idxstats.txt' files directory bam files. chrom_size_file Chromosome size file ref.size ChIP-Seq reference library size (Default: 10 million) transform Transform ChIP read counts. Options 'none' (transform), 'asinh', 'log2', 'sqrt'. bedtools_path Path bedtools executable","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_coef_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract alpha and beta coefficients from TOP posterior samples — extract_TOP_coef_samples","title":"Extract alpha and beta coefficients from TOP posterior samples — extract_TOP_coef_samples","text":"Extract alpha beta coefficients TOP posterior samples","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_coef_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract alpha and beta coefficients from TOP posterior samples — extract_TOP_coef_samples","text":"","code":"extract_TOP_coef_samples(   TOP_samples,   tf_cell_combos,   tf_name,   cell_type,   n.bins = 5,   level = c(\"bottom\", \"middle\", \"top\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_coef_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract alpha and beta coefficients from TOP posterior samples — extract_TOP_coef_samples","text":"TOP_samples TOP samples combined partitions tf_cell_combos table TF x cell type combinations tf_name TF name interest cell_type Cell type interest n.bins Number DNase ATAC bins TOP model (default = 5) level level TOP model (bottom, middle, top), 'bottom' level: TF- cell-type- specific, 'middle' level: TF-specific, cell-type generic, 'top' level: TF-generic","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_mean_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute TOP posterior mean coefficients for all three levels of TOP model — extract_TOP_mean_coef","title":"Compute TOP posterior mean coefficients for all three levels of TOP model — extract_TOP_mean_coef","text":"Compute TOP posterior mean coefficients three levels TOP model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_mean_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute TOP posterior mean coefficients for all three levels of TOP model — extract_TOP_mean_coef","text":"","code":"extract_TOP_mean_coef(TOP_samples, tf_cell_combos, n.bins = 5)"},{"path":"https://kevinlkx.github.io/TOP/reference/extract_TOP_mean_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute TOP posterior mean coefficients for all three levels of TOP model — extract_TOP_mean_coef","text":"TOP_samples TOP samples combined partitions tf_cell_combos table TF x cell type combinations n.bins Number DNase ATAC bins TOP model (default = 5)","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/filter_blacklist.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter sites in ENCODE blacklist regions — filter_blacklist","title":"Filter sites in ENCODE blacklist regions — filter_blacklist","text":"Filter sites ENCODE blacklist regions","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/filter_blacklist.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter sites in ENCODE blacklist regions — filter_blacklist","text":"","code":"filter_blacklist(sites.df, blacklist_file)"},{"path":"https://kevinlkx.github.io/TOP/reference/filter_blacklist.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter sites in ENCODE blacklist regions — filter_blacklist","text":"sites.df data frame candidate binding sites blacklist_file ENCODE blacklist file","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/filter_mapability.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — filter_mapability","title":"Title — filter_mapability","text":"Title","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/filter_mapability.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — filter_mapability","text":"","code":"filter_mapability(   sites.df = NULL,   mapability_file = NULL,   thresh_mapability = 0.8,   bigWigAverageOverBed_path = \"bigWigAverageOverBed\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/filter_mapability.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — filter_mapability","text":"sites.df data frame candidate binding sites first 6 columns BED format mapability_file ENCODE mapability bigWig file thresh_mapability Mpability filter threshold bigWigAverageOverBed_path path bigWigAverageOverBed executable","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/flank_fimo_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Get candidate sites using FIMO motifs with flanking regions — flank_fimo_sites","title":"Get candidate sites using FIMO motifs with flanking regions — flank_fimo_sites","text":"Get candidate sites using FIMO motifs flanking regions","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/flank_fimo_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get candidate sites using FIMO motifs with flanking regions — flank_fimo_sites","text":"","code":"flank_fimo_sites(fimo_file, flank = 100)"},{"path":"https://kevinlkx.github.io/TOP/reference/flank_fimo_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get candidate sites using FIMO motifs with flanking regions — flank_fimo_sites","text":"fimo_file FIMO result .txt file flank Flanking region (bp) around motif matches (default: 100)","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/get_sites_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Get count matrices around candidate sites. — get_sites_counts","title":"Get count matrices around candidate sites. — get_sites_counts","text":"Get count matrices around candidate sites.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/get_sites_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get count matrices around candidate sites. — get_sites_counts","text":"","code":"get_sites_counts(   sites_file,   genomecount_dir,   genomecount_name,   bwtool_path = \"bwtool\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/get_sites_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get count matrices around candidate sites. — get_sites_counts","text":"sites_file Filename candidate sites genomecount_dir Directory genome counts genomecount_name Filename prefix genome counts bwtool_path Path bwtool executable.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/get_total_reads.html","id":null,"dir":"Reference","previous_headings":"","what":"Get total number of mapped reads from the idxstats file generated by samtools — get_total_reads","title":"Get total number of mapped reads from the idxstats file generated by samtools — get_total_reads","text":"Get total number mapped reads idxstats file generated samtools","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/get_total_reads.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get total number of mapped reads from the idxstats file generated by samtools — get_total_reads","text":"","code":"get_total_reads(   idxstats_file,   select.chr = TRUE,   chrs = paste0(\"chr\", c(1:22)) )"},{"path":"https://kevinlkx.github.io/TOP/reference/get_total_reads.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get total number of mapped reads from the idxstats file generated by samtools — get_total_reads","text":"idxstats_file idxstats file generated samtools. select.chr TRUE, use chromosomes idxstats file. FALSE, select chromosomes chrs. chrs Chromosomes included.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/load_TOP_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Load TOP posterior samples — load_TOP_samples","title":"Load TOP posterior samples — load_TOP_samples","text":"Load TOP posterior samples","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/load_TOP_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load TOP posterior samples — load_TOP_samples","text":"","code":"load_TOP_samples(TOP_samples_file, thin = 1, n.samples = 1000)"},{"path":"https://kevinlkx.github.io/TOP/reference/load_TOP_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load TOP posterior samples — load_TOP_samples","text":"TOP_samples_file file names posterior samples partitions thin thinning rate extract posterior samples, must positive integer. n.samples Randomly choose n.samples posterior samples, number posterior samples greater n.samples","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/merge_normalize_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge counts, then normalize merged counts data. — merge_normalize_counts","title":"Merge counts, then normalize merged counts data. — merge_normalize_counts","text":"Merge counts, normalize merged counts data.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/merge_normalize_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge counts, then normalize merged counts data. — merge_normalize_counts","text":"","code":"merge_normalize_counts(counts_files, idxstats_files, ref.size = 1e+08)"},{"path":"https://kevinlkx.github.io/TOP/reference/merge_normalize_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge counts, then normalize merged counts data. — merge_normalize_counts","text":"counts_files Counts files idxstats_files idxstats files generated samtools ref.size Scale reference library size","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/millipede_binning.html","id":null,"dir":"Reference","previous_headings":"","what":"MILLIPEDE binning — millipede_binning","title":"MILLIPEDE binning — millipede_binning","text":"MILLIPEDE binning","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/millipede_binning.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MILLIPEDE binning — millipede_binning","text":"","code":"millipede_binning(counts, combine_strands = c(\"vertical\", \"motif\"))"},{"path":"https://kevinlkx.github.io/TOP/reference/millipede_binning.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MILLIPEDE binning — millipede_binning","text":"counts Counts matrix, rows candidate sites, columns DNase ATAC counts 100bp flanks around motifs forward reverse strands combine_strands Method combine counts M24 bins strands M12 bins: 'vertical' (default) 'motif'.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_bin_transform_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize, binning and transform counts — normalize_bin_transform_counts","title":"Normalize, binning and transform counts — normalize_bin_transform_counts","text":"Normalize counts library size, bin using MILLIPEDE binning method take asinh log2 transform","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_bin_transform_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize, binning and transform counts — normalize_bin_transform_counts","text":"","code":"normalize_bin_transform_counts(   count_matrix,   idxstats_file,   ref.size = 1e+08,   bin.method = c(\"M5\", \"M1\", \"M2\", \"M3\", \"M12\", \"M24\"),   transform = c(\"asinh\", \"log2\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_bin_transform_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize, binning and transform counts — normalize_bin_transform_counts","text":"count_matrix Counts matrix idxstats_file idxstats file generated samtools ref.size Scale reference library size (Default: 1e8) bin.method MILLIPEDE binning scheme (Default: 'M5'). transform asinh log2 transform","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_chip.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize and transform ChIP counts — normalize_chip","title":"Normalize and transform ChIP counts — normalize_chip","text":"Normalize transform ChIP counts","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_chip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize and transform ChIP counts — normalize_chip","text":"","code":"normalize_chip(   chip_counts,   idxstats_file,   ref.size = 1e+07,   transform = c(\"none\", \"asinh\", \"log2\", \"sqrt\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_chip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize and transform ChIP counts — normalize_chip","text":"chip_counts ChIP-seq counts idxstats_file idxstats file generated samtools ref.size ChIP-Seq reference library size (Default: 10 million) transform Transform ChIP read counts. Options 'none' (transform), 'asinh', 'log2', 'sqrt'.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_counts.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize DNase or ATAC counts — normalize_counts","title":"Normalize DNase or ATAC counts — normalize_counts","text":"Normalize DNase ATAC counts library size scaling","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_counts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize DNase or ATAC counts — normalize_counts","text":"","code":"normalize_counts(counts, idxstats_file, ref.size = 1e+08)"},{"path":"https://kevinlkx.github.io/TOP/reference/normalize_counts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize DNase or ATAC counts — normalize_counts","text":"counts count matrix idxstats_file idxstats file generated samtools ref.size Scale reference library size","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict quantitative TF occupancy or TF binding probability — predict_TOP","title":"Predict quantitative TF occupancy or TF binding probability — predict_TOP","text":"Predict quantitative TF occupancy TF binding probability using TOP model trained ChIP-seq read counts binary labels.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict quantitative TF occupancy or TF binding probability — predict_TOP","text":"","code":"predict_TOP(   data,   TOP_model,   logistic.model = FALSE,   posterior.option = c(\"mean\", \"samples\"),   transform = c(\"asinh\", \"log2\", \"log\", \"none\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict quantitative TF occupancy or TF binding probability — predict_TOP","text":"data data frame. Columns motif score DNase (ATAC) bins. Rows candidate sites. TOP_model TOP posterior samples posterior mean regression coefficients. logistic.model TRUE, use logistic version model predict TF binding probability. posterior.option 'samples': uses posterior samples, 'mean': uses posterior mean trained regression coefficients transform Method used transform ChIP-seq counts training TOP quantitative model. Options: asinh, log2, log, none. apply logistic version.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict quantitative TF occupancy or TF binding probability — predict_TOP","text":"function returns vector predicted TF occupancy.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_logistic_mean_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict TF binding probability by TOP logistic model\nwith posterior mean of regression coefficients — predict_TOP_logistic_mean_coef","title":"Predict TF binding probability by TOP logistic model\nwith posterior mean of regression coefficients — predict_TOP_logistic_mean_coef","text":"Predict TF binding probability using posterior mean regression coefficients trained TOP logistic model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_logistic_mean_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict TF binding probability by TOP logistic model\nwith posterior mean of regression coefficients — predict_TOP_logistic_mean_coef","text":"","code":"predict_TOP_logistic_mean_coef(data, mean_coef)"},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_logistic_mean_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict TF binding probability by TOP logistic model\nwith posterior mean of regression coefficients — predict_TOP_logistic_mean_coef","text":"data data frame. Columns motif score DNase (ATAC) bins. Rows candidate sites. mean_coef numeric vector. posterior mean trained regression coefficients, including intercept coefficients motif score DNase features. length(mean_coef) equal 1+ncol(data).","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_logistic_mean_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict TF binding probability by TOP logistic model\nwith posterior mean of regression coefficients — predict_TOP_logistic_mean_coef","text":"function returns vector predicted TF binding probabilities","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_mean_coef.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict TF occupancy using posterior mean of regression coefficients — predict_TOP_mean_coef","title":"Predict TF occupancy using posterior mean of regression coefficients — predict_TOP_mean_coef","text":"Predict TF occupancy using posterior mean regression coefficients trained TOP model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_mean_coef.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict TF occupancy using posterior mean of regression coefficients — predict_TOP_mean_coef","text":"","code":"predict_TOP_mean_coef(   data,   mean_coef,   transform = c(\"asinh\", \"log2\", \"log\", \"none\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_mean_coef.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict TF occupancy using posterior mean of regression coefficients — predict_TOP_mean_coef","text":"data data frame. Columns motif score DNase (ATAC) bins. Rows candidate sites. mean_coef numeric vector. posterior mean trained regression coefficients, including intercept coefficients motif score DNase features. length(mean_coef) equal 1+ncol(data). transform Method used transform ChIP-seq counts training TOP model. Options: asinh, log2, log, none.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_mean_coef.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict TF occupancy using posterior mean of regression coefficients — predict_TOP_mean_coef","text":"function returns vector predicted TF occupancy.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_samples.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict TF occupancy using posterior samples of regression coefficients — predict_TOP_samples","title":"Predict TF occupancy using posterior samples of regression coefficients — predict_TOP_samples","text":"Predict TF occupancy using posterior samples regression coefficients trained TOP model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_samples.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict TF occupancy using posterior samples of regression coefficients — predict_TOP_samples","text":"","code":"predict_TOP_samples(   data,   TOP_samples,   use.posterior.mean = FALSE,   sample.predictions = TRUE,   transform = c(\"asinh\", \"log2\", \"log\", \"none\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_samples.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict TF occupancy using posterior samples of regression coefficients — predict_TOP_samples","text":"data data frame. Columns motif score DNase (ATAC) bins. Rows candidate sites. TOP_samples TOP posterior samples. use.posterior.mean TRUE, uses posterior mean regression coefficients make predictions. sample.predictions TRUE, sample posterior predictions take mean posterior prediction samples. transform Method used transform ChIP-seq counts training TOP model. Options: asinh, log2, log, none.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/predict_TOP_samples.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict TF occupancy using posterior samples of regression coefficients — predict_TOP_samples","text":"function returns vector predicted TF occupancy.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/process_candidate_sites.html","id":null,"dir":"Reference","previous_headings":"","what":"Full process to get candidate sites from FIMO result — process_candidate_sites","title":"Full process to get candidate sites from FIMO result — process_candidate_sites","text":"Full process get candidate sites FIMO result","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/process_candidate_sites.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Full process to get candidate sites from FIMO result — process_candidate_sites","text":"","code":"process_candidate_sites(   fimo_file = NULL,   flank = 100,   thresh_pValue = 1e-05,   thresh_pwmscore = 0,   blacklist_file = NULL,   mapability_file = NULL,   thresh_mapability = 0.8,   out_file = NULL,   bigWigAverageOverBed_path = \"bigWigAverageOverBed\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/process_candidate_sites.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Full process to get candidate sites from FIMO result — process_candidate_sites","text":"fimo_file Filename FIMO result. flank Flanking region (bp) around motif matches (default: 100) thresh_pValue FIMO p-value threshold. thresh_pwmscore FIMO PWM score threshold. blacklist_file Filename blacklist regions mapability_file Filename mapability reference file bigWig format. thresh_mapability Mapability threshold (default: 0.8, include sites map-able least 80% positions). out_file Filename processed candidate sites. bigWigAverageOverBed_path Path bigWigAverageOverBed executable. needed computing mapability.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/rev_count_bwtool.html","id":null,"dir":"Reference","previous_headings":"","what":"Flip the counts generated from bwtool for motifs on the reverse (minus) strand — rev_count_bwtool","title":"Flip the counts generated from bwtool for motifs on the reverse (minus) strand — rev_count_bwtool","text":"Flip counts generated bwtool motifs reverse (minus) strand","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/rev_count_bwtool.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Flip the counts generated from bwtool for motifs on the reverse (minus) strand — rev_count_bwtool","text":"","code":"rev_count_bwtool(sites_file, fwd_matrix_file, rev_matrix_file)"},{"path":"https://kevinlkx.github.io/TOP/reference/rev_count_bwtool.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Flip the counts generated from bwtool for motifs on the reverse (minus) strand — rev_count_bwtool","text":"sites_file Filename candidate sites fwd_matrix_file Filename count matrix forward strand rev_matrix_file Filename count matrix reverse strand","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Simple scatter plot — scatterplot","title":"Simple scatter plot — scatterplot","text":"Simple scatter plot","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simple scatter plot — scatterplot","text":"","code":"scatterplot(   x,   y,   xlab = \"\",   ylab = \"\",   title = \"\",   xlim = NULL,   ylim = NULL,   color = \"black\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simple scatter plot — scatterplot","text":"x x values (measured) y y values (predicted) xlab x-axis label ylab y-axis label title title figure xlim range x-axis values ylim range y-axis values color color dots","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot_predictions.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a scatter plot of measured and predicted occupancy — scatterplot_predictions","title":"Make a scatter plot of measured and predicted occupancy — scatterplot_predictions","text":"Make scatter plot measured predicted occupancy","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot_predictions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a scatter plot of measured and predicted occupancy — scatterplot_predictions","text":"","code":"scatterplot_predictions(   x,   y,   xlab = \"measured\",   ylab = \"predicted\",   title = \"\",   xlim = c(0, 10),   ylim = c(0, 10),   color = \"black\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/scatterplot_predictions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a scatter plot of measured and predicted occupancy — scatterplot_predictions","text":"x x values (measured) y y values (predicted) xlab x-axis label ylab y-axis label title title figure xlim range x-axis values ylim range y-axis values color color dots","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/select_features.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract PWM and bin features — select_features","title":"Extract PWM and bin features — select_features","text":"Extract PWM bin features","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/select_features.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract PWM and bin features — select_features","text":"","code":"select_features(data, pwm.name = \"pwm\", bin.name = \"bin\")"},{"path":"https://kevinlkx.github.io/TOP/reference/select_features.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract PWM and bin features — select_features","text":"data Input data frame pwm.name column name (prefix) PMW score bin.name column name (prefix) DNase ATAC bins","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/select_model_coef_mean.html","id":null,"dir":"Reference","previous_headings":"","what":"Select TOP model hierarchy level — select_model_coef_mean","title":"Select TOP model hierarchy level — select_model_coef_mean","text":"TF motif available training data model_level='best', use TF-specific model TF motif; otherwise, use top level TF-generic model.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/select_model_coef_mean.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Select TOP model hierarchy level — select_model_coef_mean","text":"","code":"select_model_coef_mean(   pwm_id,   cell_type,   tf_pwm_training_list,   model_coefficients,   model_level = c(\"best\", \"bottom\", \"middle\", \"top\") )"},{"path":"https://kevinlkx.github.io/TOP/reference/select_model_coef_mean.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Select TOP model hierarchy level — select_model_coef_mean","text":"pwm_id Motif PWM ID cell_type Cell type tf_pwm_training_list List TF motifs available coefficients trained. model_coefficients Trained TOP model regression coefficients model_level Specific TOP model hierarchy level: 'top', 'bottom', 'middle', 'best'. Default: 'best', lowest hierarchy level model used.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/sort_merge_overlap_bedgraph.html","id":null,"dir":"Reference","previous_headings":"","what":"Sort and merge the overlapping sites,\nremove the overlapping sites with lower occupancy — sort_merge_overlap_bedgraph","title":"Sort and merge the overlapping sites,\nremove the overlapping sites with lower occupancy — sort_merge_overlap_bedgraph","text":"Sort merge overlapping sites, remove overlapping sites lower occupancy","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/sort_merge_overlap_bedgraph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sort and merge the overlapping sites,\nremove the overlapping sites with lower occupancy — sort_merge_overlap_bedgraph","text":"","code":"sort_merge_overlap_bedgraph(predicted_bedgraph.df)"},{"path":"https://kevinlkx.github.io/TOP/reference/sort_merge_overlap_bedgraph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sort and merge the overlapping sites,\nremove the overlapping sites with lower occupancy — sort_merge_overlap_bedgraph","text":"predicted_bedgraph.df predicted TF occupancy bedgraph format","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/track_def_line.html","id":null,"dir":"Reference","previous_headings":"","what":"Set genome browser track parameters for predictions in bedGraph format — track_def_line","title":"Set genome browser track parameters for predictions in bedGraph format — track_def_line","text":"Set genome browser track parameters predictions bedGraph format","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/track_def_line.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set genome browser track parameters for predictions in bedGraph format — track_def_line","text":"","code":"track_def_line(   tf_name,   pwm_id,   cell_type,   rep_name,   type_model,   viewMax = 100,   mycolor = \"0,0,0\" )"},{"path":"https://kevinlkx.github.io/TOP/reference/track_def_line.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set genome browser track parameters for predictions in bedGraph format — track_def_line","text":"tf_name TF name pwm_id PWM ID cell_type cell type rep_name replicate name type_model model type viewMax upper limit view TF occupancy genome browser mycolor color track","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_M5_model_jags.html","id":null,"dir":"Reference","previous_headings":"","what":"Train TOP model — train_TOP_M5_model_jags","title":"Train TOP model — train_TOP_M5_model_jags","text":"Train TOP model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_M5_model_jags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train TOP model — train_TOP_M5_model_jags","text":"","code":"train_TOP_M5_model_jags(   data,   model,   n.iter = 10000,   n.burnin = 5000,   n.chains = 3,   n.thin = 10 )"},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_M5_model_jags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train TOP model — train_TOP_M5_model_jags","text":"data combined training data. model TOP model (written BUGS code). n.iter number total iterations per chain (including burn ). n.burnin length burn , .e. number iterations discard beginning. n.chains number Markov chains. n.thin thinning rate, must positive integer.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_logistic_M5_model_jags.html","id":null,"dir":"Reference","previous_headings":"","what":"Train TOP logistic model — train_TOP_logistic_M5_model_jags","title":"Train TOP logistic model — train_TOP_logistic_M5_model_jags","text":"Train TOP logistic model","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_logistic_M5_model_jags.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train TOP logistic model — train_TOP_logistic_M5_model_jags","text":"","code":"train_TOP_logistic_M5_model_jags(   data,   model,   n.iter = 10000,   n.burnin = 5000,   n.chains = 3,   n.thin = 10 )"},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_logistic_M5_model_jags.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train TOP logistic model — train_TOP_logistic_M5_model_jags","text":"data combined training data. model TOP logistic model (written BUGS code). n.iter number total iterations per chain (including burn ). n.burnin length burn , .e. number iterations discard beginning. n.chains number Markov chains. n.thin thinning rate, must positive integer.","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Train TOP model for each partition separately — train_TOP_model","title":"Train TOP model for each partition separately — train_TOP_model","text":"Train TOP model partition separately","code":""},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train TOP model for each partition separately — train_TOP_model","text":"","code":"train_TOP_model(   model_file,   training_data_dir,   training_data_name,   logistic.model = FALSE,   out_dir,   partitions = 1:10,   n.iter = 10000,   n.burnin = 5000,   n.chains = 3,   n.thin = 10 )"},{"path":"https://kevinlkx.github.io/TOP/reference/train_TOP_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Train TOP model for each partition separately — train_TOP_model","text":"model_file TOP logistic model file. training_data_dir Directory saving training data training_data_name Prefix training data file names logistic.model TRUE, use logistic version model out_dir Output directory TOP model posterior samples partitions select partition(s) run n.iter number total iterations per chain (including burn ). n.burnin length burn , .e. number iterations discard beginning. n.chains number Markov chains. n.thin thinning rate, must positive integer.","code":""}]
